foundation_model:
  # Recognize-Anything Model PLUS
  ram_checkpoint: '../pretrains/foundation_models/ram_plus_swin_large_14m.pth'
  # Grounding DINO
  grounded_config_file: './segmenter2d/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py'
  grounded_checkpoint: '../pretrains/foundation_models/groundingdino_swint_ogc.pth'
  box_threshold: 0.4
  text_threshold: 0.4
  # YOLO-World
  yoloworld_config_file: './segmenter2d/YOLO-World/configs/pretrain/yolo_world_v2_x_vlpan_bn_2e-3_100e_4x8gpus_obj365v1_goldg_train_lvis_minival.py'
  yoloworld_checkpoint: '../pretrains/foundation_models/yolo_world_v2_x_obj365v1_goldg_cc3mlite_pretrain_1280ft-14996a36.pth'
  # Segment Anything Model
  sam_checkpoint: '../pretrains/foundation_models/sam_vit_h_4b8939.pth'
  # CLIP
  clip_model: 'ViT-L/14@336px'
  device: 'cuda'
  clip_dim: 768

### Current supported segmenter2ds
# ['Grounded-SAM': GDino + SAM || 
# 'RAM Grounded-SAM': RAM + GDino + SAM || 
# 'YoloW-SAM': YOLO-World + SAM ||
# 'RAM YoloW-SAM: RAM+ YOLO-World + SAM]'
###
segmenter2d:
  model: 'Grounded-SAM' # select 2D segmenter

grounded_feature:
  granularity: 0.8

data:
  dataset_name: 'replica'
  split_path: './open3dis/dataset/replica_8scenes.txt'
  datapath: './data/replica/replica_2d'
  gt_pth: './data/replica/replica_3d'
  original_ply: './data/replica/replica_plys'
  spp_path: './data/replica/replica_spp_new'
  cls_agnostic_3d_proposals_path: './data/replica/cls_agnostic_replica_scannet200'
  dc_features_path: './data/replica/dc_feat_replica_scannet200'
  img_dim: [640, 360]
  rgb_img_dim: [640, 360]
  cut_num_pixel_boundary: 10
  img_interval: 1
  num_classes: 48

cluster:
  visi: 0.5
  recall: 0.5 # recall
  simi: 0.5
  point_visi: 0.0
  valid_points: 50
  iterative: False

refine_grounding:
  top_k: 5

final_instance:
  spp_level: False # Turning this flag on use spp lifting ||  pointwise lifting
  duplicate: True
  iou_overlap: 0.9
  top_k: 300
  scale_semantic_score: 300.0

exp:
  exp_name: "version_8scenes"
  mask2d_output: 'maskGdino'
  grounded_feat_output: 'grounded_feat'
  refined_grounded_feat_output: 'refined_grounded_feat'
  clustering_3d_output: 'hier_agglo'
  final_output: 'final_result_hier_agglo'
  save_dir: './exp'

proposals:
  p2d: True # 2D branch
  p3d: False # 3D branch
  agnostic: False # returning class-agnostic masks (without class + scores)
  refined: True # feature branch, setting this True uses refined feature, else uses feature from 2D branch
                # refer to VinAI-3DIS solution (two-stage feature): https://arxiv.org/pdf/2402.15321.pdf 

evaluate:
  evalvocab: False # AP evaluation for OV-3DIS
  evalagnostic: False # AP evaluation for agnostic 3DIS

fp16: True